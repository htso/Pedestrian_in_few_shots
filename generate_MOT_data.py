# This script creates a dataset in the appropriate directory structure for use in the few-shot learning algorithm Neural Statistician. 
#
# It requires the following items,
#
#    1. the 'hypotheses' text file generated by deep_sort_app.py, which has the pedestrian object tracking information
#    2. the video frames correspond to the data in the hypotheses text file
# 
# It creates the following directory structure :
#
#                                          out_dir
#                                             |
#             -----------------------------------------------------------------
#             |                          |                                    |
#          PERSON103                 PERSON107          ....              PERSON159
#             |                          |                                    |
#           VIDEO                      VIDEO                                VIDEO
#             |                          |                                    | 
#        P103Fr309.jpg              P107Fr336.jpg                       P159Fr517.jpg
#        P103Fr310.jpg              P107Fr337.jpg                       P159Fr518.jpg
#            ...                       ....                                  ...
#
#
import argparse
import sys
import os
import time
import math
import numpy as np
import cv2
from PIL import Image
import pathlib

# the_video = 'MOT16-03'
# detected_fnm = 'MOT1603_hypotheses.txt'
# video_dir = '/mnt/ClearWaterBay/Deep_SORT_data/MOT16/test/'
# out_dir = '/mnt/ClearWaterBay/Deep_SORT_data/'

# ===== Timothy's code =============================================================
def merge_image(img1, img2):
    shape1 = img1.shape[:-1]
    shape2 = img2.shape[:-1]
    assert img1.shape[-1]==img2.shape[-1]==3
    outimage = np.zeros((max(shape1[0], shape2[0]), max(shape1[1], shape2[1]), 3))
    for i in range(3):
        outimage[:shape2[0], :shape2[1], i] = img2[:, :, i]
        outimage[:shape1[0], :shape1[1], i] = img1[:, :, i]
    return outimage
# ==================================================================================

def scale_to_fit(img, max_height, max_width): 
    h = img.shape[0]
    w = img.shape[1]
    a_w = max_width / w
    a_h = max_height / h
    a_ratio = min(a_w, a_h)
    # scale the image with the same aspect ratio (a_ratio)
    img_scaled = cv2.resize(img, None, fx=a_ratio, fy=a_ratio, interpolation=cv2.INTER_CUBIC)
    return img_scaled

def run(the_video, detected_fnm, max_width, max_height, video_dir, out_dir, verbose=False):
    print('video : ', the_video)

    image_dir = video_dir + '/' + the_video + '/' + 'img1'
    image_filenames = {
        int(os.path.splitext(f)[0]): os.path.join(image_dir, f)
        for f in os.listdir(image_dir)}

    det_mat = np.loadtxt(detected_fnm, delimiter=',')
    blank_mask = np.zeros((max_height, max_width, 3))

    N = det_mat.shape[0]
    print('N :', N)
    fr_ix = np.sort(np.unique(det_mat[:,0]), axis=0)
    print('fr_ix shape :', fr_ix.shape)
    person_ix = np.sort(np.unique(det_mat[:,1]), axis=0)
    person_ix = person_ix.astype(int)
    print('person_ix shape :', person_ix.shape)
    Nfr = fr_ix.shape[0]
    Nperson = person_ix.shape[0]
    Nlabel = Nperson
    print('Nfr : %d\t Nperson : %d\t Nlabel : %d\n' %(Nfr, Nperson, Nlabel))

    # Skip a person if it has fewer than 20 frames
    per_ix = []
    for i in range(len(person_ix)):
        if len(np.where(det_mat[:,1] == person_ix[i])[0]) > 20:
            per_ix.append(person_ix[i])
    print('Person with more than 20 frames :')
    print(per_ix)

    for i in range(len(fr_ix)): # loop thru the 1500 frames of a video
        if verbose is True:
            print('i :', i)
        # get the file name of the image frame
        fnm = image_filenames[fr_ix[i]]
        # load the image, which is just a 3D numpy array
        img = cv2.imread(fnm)
        # find all the persons in this image
        ix = np.where(det_mat[:,0] == fr_ix[i])[0]
        for j in range(len(ix)): # loop thru all the persons 
            if verbose is True:
                print('j : ', j)
            this_guy = int(det_mat[ix[j],1])
            # skip if this person is not in the per_ix list
            if this_guy not in per_ix:
                continue

            person_dir = out_dir + '/PERSON' + str(this_guy) + '/VIDEO'
            pathlib.Path(person_dir).mkdir(parents=True, exist_ok=True) 

            x = int(det_mat[ix[j],2])
            y = int(det_mat[ix[j],3])
            w = int(det_mat[ix[j],4])
            h = int(det_mat[ix[j],5])
            x = max(x, 0)
            y = max(y, 0)
            img1 = img[y:(y+h),x:(x+w),:]
            img_s = scale_to_fit(img1, 160, 96)
            img2 = merge_image(img_s, blank_mask)
            img2 = img2.astype(np.uint8)
            im = Image.fromarray(img2)
            vnm = person_dir + '/' + 'P' + str(this_guy) + 'Fr' + str(i) + '.jpg'
            im.save(vnm)


def parse_args():
    parser = argparse.ArgumentParser(description="Create MOT16 video dataset for Neural Statistician")
    parser.add_argument(
        "--the_video", help="One of the 7 videos, eg. MOT16-03", default='MOT16-08', required=True)
    parser.add_argument(
        "--detection_file", help="Name of the detection txt file, eg. MOT1603_hypotheses.txt.", default='MOT1608_hypotheses.txt', required=True)
    parser.add_argument(
        "--video_dir", help="Path to the video.", default="/mnt/ClearWaterBay/Deep_SORT_data/MOT16/test", required=True)
    parser.add_argument(
        "--out_dir", help="Top directory to create the subdirectories for each person and write the frame images.", default="/mnt/ClearWaterBay/Deep_SORT_data/MOT16_for_NeuralStat", required=True)
    parser.add_argument(
        "--max_height", help="Maximum height of the final image to be used in Neural Statistician", default=160, type=int)
    parser.add_argument(
        "--max_width", help="Maximum width of the final image to be used in Neural Statistician", default=96, type=int)
    return parser.parse_args()


if __name__ == "__main__":
    args = parse_args()
    run(args.the_video, args.detection_file, args.max_width, args.max_height, args.video_dir, args.out_dir, verbose=False)
